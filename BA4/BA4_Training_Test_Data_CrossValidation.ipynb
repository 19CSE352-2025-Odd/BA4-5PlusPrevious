{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" many algorithms will execute faster with smaller samples.\n",
    "Accurate models can often be built with as few as several thousand records. Hence, we\n",
    "will want to sample a subset of records for model building.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a csv file to a dataFrame WestRox\n",
    "housing_df = pd.read_csv('https://raw.githubusercontent.com/reisanar/datasets/master/WestRoxbury.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.to_csv('E:/WestRoxbury.csv')   # writing to E drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL VALUE</th>\n",
       "      <th>TAX</th>\n",
       "      <th>LOT SQFT</th>\n",
       "      <th>YR BUILT</th>\n",
       "      <th>GROSS AREA</th>\n",
       "      <th>LIVING AREA</th>\n",
       "      <th>FLOORS</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULL BATH</th>\n",
       "      <th>HALF BATH</th>\n",
       "      <th>KITCHEN</th>\n",
       "      <th>FIREPLACE</th>\n",
       "      <th>REMODEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344.2</td>\n",
       "      <td>4330</td>\n",
       "      <td>9965</td>\n",
       "      <td>1880</td>\n",
       "      <td>2436</td>\n",
       "      <td>1352</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412.6</td>\n",
       "      <td>5190</td>\n",
       "      <td>6590</td>\n",
       "      <td>1945</td>\n",
       "      <td>3108</td>\n",
       "      <td>1976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Recent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOTAL VALUE    TAX  LOT SQFT   YR BUILT  GROSS AREA   LIVING AREA  FLOORS   \\\n",
       "0         344.2  4330       9965      1880         2436         1352      2.0   \n",
       "1         412.6  5190       6590      1945         3108         1976      2.0   \n",
       "\n",
       "   ROOMS  BEDROOMS   FULL BATH  HALF BATH  KITCHEN  FIREPLACE REMODEL  \n",
       "0      6          3          1          1        1          0    None  \n",
       "1     10          4          2          1        1          0  Recent  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(housing_df.REMODEL.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.REMODEL.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL VALUE</th>\n",
       "      <th>TAX</th>\n",
       "      <th>LOT SQFT</th>\n",
       "      <th>YR BUILT</th>\n",
       "      <th>GROSS AREA</th>\n",
       "      <th>LIVING AREA</th>\n",
       "      <th>FLOORS</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULL BATH</th>\n",
       "      <th>HALF BATH</th>\n",
       "      <th>KITCHEN</th>\n",
       "      <th>FIREPLACE</th>\n",
       "      <th>REMODEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>381.5</td>\n",
       "      <td>4799</td>\n",
       "      <td>5275</td>\n",
       "      <td>1930</td>\n",
       "      <td>2616</td>\n",
       "      <td>1568</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>392.5</td>\n",
       "      <td>4937</td>\n",
       "      <td>5429</td>\n",
       "      <td>1930</td>\n",
       "      <td>2704</td>\n",
       "      <td>1544</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TOTAL VALUE    TAX  LOT SQFT   YR BUILT  GROSS AREA   LIVING AREA  \\\n",
       "1956         381.5  4799       5275      1930         2616         1568   \n",
       "2189         392.5  4937       5429      1930         2704         1544   \n",
       "\n",
       "      FLOORS   ROOMS  BEDROOMS   FULL BATH  HALF BATH  KITCHEN  FIREPLACE  \\\n",
       "1956      2.0      6          3          1          1        1          1   \n",
       "2189      2.0      7          3          1          0        1          0   \n",
       "\n",
       "     REMODEL  \n",
       "1956    None  \n",
       "2189    None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TOTAL VALUE ', 'TAX', 'LOT SQFT ', 'YR BUILT', 'GROSS AREA ',\n",
       "       'LIVING AREA', 'FLOORS ', 'ROOMS', 'BEDROOMS ', 'FULL BATH',\n",
       "       'HALF BATH', 'KITCHEN', 'FIREPLACE', 'REMODEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.columns # print a list of variables\n",
    "# REMODEL needs to be converted to a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.columns = [s.strip().replace(\" \" , \"_\") for s in housing_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.REMODEL = housing_df.REMODEL.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['None', 'Old', 'Recent'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.REMODEL.cat.categories # Show number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['None', 'Old', 'Recent'], ordered=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.REMODEL.dtype # Check type of converted variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dummy Variables in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TOTAL_VALUE', 'TAX', 'LOT_SQFT', 'YR_BUILT', 'GROSS_AREA',\n",
       "       'LIVING_AREA', 'FLOORS', 'ROOMS', 'BEDROOMS', 'FULL_BATH', 'HALF_BATH',\n",
       "       'KITCHEN', 'FIREPLACE', 'REMODEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use drop_first=True to drop the first dummy variable (There are 3 ie 'None', 'Old', 'Recent')\n",
    "housing_df = pd.get_dummies(housing_df, prefix_sep=\"_\", drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TOTAL_VALUE', 'TAX', 'LOT_SQFT', 'YR_BUILT', 'GROSS_AREA',\n",
       "       'LIVING_AREA', 'FLOORS', 'ROOMS', 'BEDROOMS', 'FULL_BATH', 'HALF_BATH',\n",
       "       'KITCHEN', 'FIREPLACE', 'REMODEL_Old', 'REMODEL_Recent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REMODEL_Old</th>\n",
       "      <th>REMODEL_Recent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REMODEL_Old  REMODEL_Recent\n",
       "0            0               0\n",
       "1            0               1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.loc[:, \"REMODEL_Old\":\"REMODEL_Recent\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The median is used for imputation, rather than the mean, to preserve the\n",
    "#integer nature of the counts for bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([5762, 2614, 2875, 5401, 2131, 5416, 5225, 1530, 1377, 382], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To illustrate missing data procedures, we first convert a few entries for\n",
    "# bedrooms to NA’s. Then we impute these missing values using the median of the\n",
    "# remaining values.\n",
    "missingRows = housing_df.sample(10).index\n",
    "missingRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.loc[missingRows, \"BEDROOMS\"] = np.nan  # removing the values for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with valid BEDROOMS values after setting to NAN:  5792\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows with valid BEDROOMS values after setting to NAN: \",housing_df[\"BEDROOMS\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values\n",
    "reduced_df = housing_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing rows with missing values:  5792\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows after removing rows with missing values: \",len(reduced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values using the median of the remaining values.\n",
    "medianBedrooms = housing_df[\"BEDROOMS\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medianBedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.BEDROOMS = housing_df.BEDROOMS.fillna(value=medianBedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with valid BEDROOMS values after filling NA values:  5802\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows with valid BEDROOMS values after filling NA values: \",housing_df[\"BEDROOMS\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalizing (Standardizing) and Rescaling Data. This operation is also sometimes called standardizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using the methods mean and std; (df - df.mean()) / df.std(). In effect, we\n",
    "are expressing each value as the “number of standard deviations away from the mean,”\n",
    "also called a z-score. An alternative is the class StandardScaler(), which is one of a\n",
    "number different transformers available in scikit-learn. You can use the methods fit() or\n",
    "fit_transform() to train the transformer on the training set and the method transform()\n",
    "to apply on the validation set. The result of the transformation is no longer a pandas\n",
    "dataframe, however, you can convert it back into one easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_df...Now take out the last column...error in \" norm_df = (housing_df - housing_df.mean()) / housing_df.std()\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = housing_df.iloc[:,0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_VALUE</th>\n",
       "      <th>TAX</th>\n",
       "      <th>LOT_SQFT</th>\n",
       "      <th>YR_BUILT</th>\n",
       "      <th>GROSS_AREA</th>\n",
       "      <th>LIVING_AREA</th>\n",
       "      <th>FLOORS</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULL_BATH</th>\n",
       "      <th>HALF_BATH</th>\n",
       "      <th>KITCHEN</th>\n",
       "      <th>FIREPLACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344.2</td>\n",
       "      <td>4330</td>\n",
       "      <td>9965</td>\n",
       "      <td>1880</td>\n",
       "      <td>2436</td>\n",
       "      <td>1352</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412.6</td>\n",
       "      <td>5190</td>\n",
       "      <td>6590</td>\n",
       "      <td>1945</td>\n",
       "      <td>3108</td>\n",
       "      <td>1976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOTAL_VALUE   TAX  LOT_SQFT  YR_BUILT  GROSS_AREA  LIVING_AREA  FLOORS  \\\n",
       "0        344.2  4330      9965      1880        2436         1352     2.0   \n",
       "1        412.6  5190      6590      1945        3108         1976     2.0   \n",
       "\n",
       "   ROOMS  BEDROOMS  FULL_BATH  HALF_BATH  KITCHEN  FIREPLACE  \n",
       "0      6       3.0          1          1        1          0  \n",
       "1     10       4.0          2          1        1          0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = (pp - pp.mean())/ pp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_VALUE</th>\n",
       "      <th>TAX</th>\n",
       "      <th>LOT_SQFT</th>\n",
       "      <th>YR_BUILT</th>\n",
       "      <th>GROSS_AREA</th>\n",
       "      <th>LIVING_AREA</th>\n",
       "      <th>FLOORS</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>FULL_BATH</th>\n",
       "      <th>HALF_BATH</th>\n",
       "      <th>KITCHEN</th>\n",
       "      <th>FIREPLACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.488879</td>\n",
       "      <td>-0.488507</td>\n",
       "      <td>1.381019</td>\n",
       "      <td>-1.576690</td>\n",
       "      <td>-0.552998</td>\n",
       "      <td>-0.564458</td>\n",
       "      <td>0.710905</td>\n",
       "      <td>-0.691980</td>\n",
       "      <td>-0.271728</td>\n",
       "      <td>-0.568528</td>\n",
       "      <td>0.723202</td>\n",
       "      <td>-0.124803</td>\n",
       "      <td>-1.309337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200795</td>\n",
       "      <td>0.200789</td>\n",
       "      <td>0.116835</td>\n",
       "      <td>0.229372</td>\n",
       "      <td>0.207196</td>\n",
       "      <td>0.590121</td>\n",
       "      <td>0.710905</td>\n",
       "      <td>2.090325</td>\n",
       "      <td>0.910104</td>\n",
       "      <td>1.347035</td>\n",
       "      <td>0.723202</td>\n",
       "      <td>-0.124803</td>\n",
       "      <td>-1.309337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOTAL_VALUE       TAX  LOT_SQFT  YR_BUILT  GROSS_AREA  LIVING_AREA  \\\n",
       "0    -0.488879 -0.488507  1.381019 -1.576690   -0.552998    -0.564458   \n",
       "1     0.200795  0.200789  0.116835  0.229372    0.207196     0.590121   \n",
       "\n",
       "     FLOORS     ROOMS  BEDROOMS  FULL_BATH  HALF_BATH   KITCHEN  FIREPLACE  \n",
       "0  0.710905 -0.691980 -0.271728  -0.568528   0.723202 -0.124803  -1.309337  \n",
       "1  0.710905  2.090325  0.910104   1.347035   0.723202 -0.124803  -1.309337  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalizing is one way to bring all variables to the same scale. Another popular approach\n",
    "is rescaling each variable to a [0, 1] scale. This is done by subtracting the minimum value\n",
    "and then dividing by the range. Subtracting the minimum shifts the variable origin to\n",
    "zero. Dividing by the range shrinks or expands the data to the range [0, 1]. In pandas, use\n",
    "the expression (df-df.min())/ (df.max()-df.min())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = (pp - pp.min()) / (pp.max() - pp.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer pp65 for scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" To consider why normalizing or scaling to [0, 1] might be necessary, consider the case of\n",
    "clustering. Clustering typically involves calculating a distance measure that reflects how\n",
    "far each record is from a cluster center or from other records. With multiple variables,\n",
    "different units will be used: days, dollars, counts, and so on. If the dollars are in the\n",
    "thousands and everything else is in the tens, the dollar variable will come to dominate the\n",
    "distance measure. Moreover, changing units from, say, days to hours or months, could\n",
    "alter the outcome completely.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.5 Predictive Power and Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In supervised learning, a key question presents itself: How well will our prediction or\n",
    "classification model perform when we apply it to new data? We are particularly interested\n",
    "in comparing the performance of various models so that we can choose the one we think\n",
    "will do the best when it is implemented in practice. A key concept is to make sure that our\n",
    "chosen model generalizes beyond the dataset that we have at hand. To assure\n",
    "generalization, we use the concept of data partitioning and try to avoid overfitting. These\n",
    "two important concepts are described next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfitting ---Overfitting: This function fits the data with no error see pp67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Somewhat surprisingly, even if we know for a fact that a higher-degree curve is the\n",
    "appropriate model, if the model-fitting dataset is not large enough, a lower-degree\n",
    "function (that is not as likely to fit the noise) is likely to perform better in terms of\n",
    "predicting new values. Overfitting can also result from the application of many different\n",
    "models, from which the best performing model is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creation and Use of Data Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training Partition\n",
    "The training partition, typically the largest partition, contains the data used to build the\n",
    "various models we are examining. The same training partition is generally used to\n",
    "develop multiple models.\n",
    "Validation Partition\n",
    "The validation partition (sometimes called the test partition) is used to assess the\n",
    "predictive performance of each model so that you can compare models and choose the\n",
    "best one. In some algorithms (e.g., classification and regression trees, k-nearest\n",
    "neighbors), the validation partition may be used in an automated fashion to tune and\n",
    "improve the model.\n",
    "Test Partition\n",
    "The test partition (sometimes called the holdout or evaluation partition) is used to assess\n",
    "the performance of the chosen model with new data.\n",
    "Why have both a validation and a test partition? When we use the validation data to\n",
    "assess multiple models and then choose the model that performs best with the validation\n",
    "data, we again encounter another (lesser) facet of the overfitting problem—chance aspects\n",
    "of the validation data that happen to match the chosen model better than they match\n",
    "other models. In other words, by using the validation data to choose one of several\n",
    "models, the performance of the chosen model on the validation data will be overly\n",
    "optimistic.\n",
    "The random features of the validation data that enhance the apparent performance of the\n",
    "chosen model will probably not be present in new data to which the model is applied.\n",
    "Therefore, we may have overestimated the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, validData = train_test_split(housing_df, test_size=0.40,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is train_test_split?\n",
    "train_test_split is a function in Sklearn model selection for splitting data arrays into two subsets: \n",
    "for training data and for testing data. With this function, you don't need to divide the dataset manually.\n",
    "By default, Sklearn train_test_split will make random partitions for the two subsets. \n",
    "However, you can also specify a random state for the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split(X, y, train_size=0.*,test_size=0.*, random_state=*)\n",
    "X, y. The first parameter is the dataset you're selecting to use.\n",
    "train_size. This parameter sets the size of the training dataset. There are three options: None, which is the default, Int, which requires the exact number of samples, and float, which ranges from 0.1 to 1.0.\n",
    "test_size. This parameter specifies the size of the testing dataset. The default state suits the training size. It will be set to 0.25 if the training size is set to default.\n",
    "random_state. The default mode performs a random split using np.random. Alternatively, you can add an integer using an exact number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "trainData, validData = model_selection.train_test_split(housing_df, test_size=0.40,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :  (3481, 15)\n",
      "Validation :  (2321, 15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training : \", trainData.shape)\n",
    "print(\"Validation : \", validData.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training (50; and then splitting validation 40% and test 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training (50\n",
    "trainData, temp = model_selection.train_test_split(housing_df, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "validData, testData = model_selection.train_test_split(temp, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :  (2901, 15)\n",
      "Test :  (1161, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training : \", trainData.shape)\n",
    "print(\"Test : \", testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross-Validation\n",
    "When the number of records in our sample is small, data partitioning might not be\n",
    "advisable as each partition will contain too few records for model building and\n",
    "performance evaluation. Furthermore, some data mining methods are sensitive to small\n",
    "changes in the training data, so that a different partitioning can lead to different results.\n",
    "An alternative to data partitioning is cross-validation, which is especially useful with\n",
    "small samples. Cross-validation, or k-fold cross-validation, is a procedure that starts with\n",
    "partitioning the data into “folds,” or non-overlapping subsamples. Often we choose k = 5\n",
    "folds, meaning that the data are randomly partitioned into five equal parts, where each\n",
    "fold has 20% of the observations. A model is then fit k times. Each time, one of the folds\n",
    "is used as the validation set and the remaining k − 1 folds serve as the training set. The\n",
    "result is that each fold is used once as the validation set, thereby producing predictions\n",
    "for every observation in the dataset. We can then combine the model’s predictions on\n",
    "each of the k validation sets in order to evaluate the overall performance of the model. In\n",
    "Python, cross-validation is achieved using the cross_val_score() or the more general\n",
    "cross_validate function, where argument cv determines the number of folds. Sometimes\n",
    "cross-validation is built into a data mining algorithm, with the results of the crossvalidation\n",
    "used for choosing the algorithm’s parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
