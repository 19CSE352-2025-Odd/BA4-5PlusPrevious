{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfb0343",
   "metadata": {},
   "source": [
    "# BA5b: Diagnostics and Transformations for Predictive Modeling\n",
    "\n",
    "This notebook builds on BA5 and BA5a to evaluate whether the **assumptions of linear regression** are met and explore **transformations** to improve model performance and validity.\n",
    "\n",
    "Topics covered:\n",
    "- Residual analysis\n",
    "- Detecting skewness in predictors and response\n",
    "- Applying transformations (log, sqrt)\n",
    "- Checking multicollinearity (VIF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57448bb",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "Same dataset from BA5. We'll fit a linear regression model and perform diagnostics on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_df = pd.read_csv(\"/mnt/data/WestRoxbury.csv\")\n",
    "housing_df = housing_df.drop(columns=[\"TAX\"])\n",
    "housing_df = pd.get_dummies(housing_df, columns=[\"REMODEL\"], drop_first=True)\n",
    "housing_df[\"FLOORS\"] = housing_df[\"FLOORS\"].replace(15, 1.5)\n",
    "\n",
    "X = housing_df.drop(columns=[\"TOTAL_VALUE\"])\n",
    "y = housing_df[\"TOTAL_VALUE\"]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409503f",
   "metadata": {},
   "source": [
    "## 2. Fit the Linear Model and View Residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeabbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(valid_X)\n",
    "residuals = valid_y - pred_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afdf462",
   "metadata": {},
   "source": [
    "## 3. Residual Plot\n",
    "\n",
    "A good model will have residuals that are **randomly scattered** around zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(pred_y, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cf153",
   "metadata": {},
   "source": [
    "## 4. Check for Skewness in Target Variable\n",
    "\n",
    "Heavily skewed response variables can distort model estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdcb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(train_y, kde=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537f6b2",
   "metadata": {},
   "source": [
    "## 5. Apply Log Transformation to Target and Refit Model\n",
    "\n",
    "Letâ€™s try modeling `log(TOTAL_VALUE)` instead of `TOTAL_VALUE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_y = np.log(train_y)\n",
    "log_valid_y = np.log(valid_y)\n",
    "\n",
    "log_model = LinearRegression()\n",
    "log_model.fit(train_X, log_train_y)\n",
    "log_pred = log_model.predict(valid_X)\n",
    "\n",
    "# Convert back to original scale\n",
    "reverted_pred = np.exp(log_pred)\n",
    "log_rmse = np.sqrt(mean_squared_error(valid_y, reverted_pred))\n",
    "\n",
    "print(f\"Log-transformed Model RMSE: ${log_rmse:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be18f2d",
   "metadata": {},
   "source": [
    "## 6. Check for Multicollinearity using VIF\n",
    "\n",
    "High VIF values (> 5 or 10) suggest multicollinearity, which can destabilize coefficient estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01645a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_const = sm.add_constant(train_X)\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"Feature\"] = train_X.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(X_const.values, i+1) for i in range(len(train_X.columns))]\n",
    "vif_df.sort_values(\"VIF\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57801cad",
   "metadata": {},
   "source": [
    "## ðŸ§ª Challenges\n",
    "\n",
    "1. Try applying log or sqrt transformation to one or more **predictors**.\n",
    "2. Drop high-VIF variables and refit the model. Observe changes in RMSE.\n",
    "3. Combine transformed predictors and response in one model.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
